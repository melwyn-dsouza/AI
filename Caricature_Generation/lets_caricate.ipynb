{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricature Generation - Melwyn DSouza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN):\n",
    "\n",
    "An image-to-image generator in AI and machine learning is a type of model that takes an input image and generates an output image with a desired transformation. This transformation could include tasks such as image-to-image translation, style transfer, image super-resolution, and more. These models are typically built using deep learning techniques, and one popular architecture for such tasks is the Generative Adversarial Network (GAN). Let's break down how this type of model works:\n",
    "\n",
    "Generative Adversarial Network (GAN):\n",
    "A GAN consists of two main components: a generator and a discriminator. These components are trained simultaneously in a competitive process, where the generator tries to create realistic images, and the discriminator tries to distinguish between real and generated images.\n",
    "Generator: The generator takes a random noise vector or an input image and attempts to transform it into an image that resembles the target domain. For example, if the task is image-to-image translation from a day scene to a night scene, the generator would take a day scene image and create a corresponding night scene image.\n",
    "\n",
    "Discriminator: The discriminator's role is to differentiate between real images from the target domain and fake images produced by the generator. It is trained to assign high probabilities to real images and low probabilities to generated images.\n",
    "\n",
    "Training Process:\n",
    "The training process involves a back-and-forth competition between the generator and the discriminator:\n",
    "\n",
    "Step 1: Generator's Training: The generator takes an input image and produces a generated image. This generated image, along with real images from the target domain, is fed into the discriminator. The generator aims to create images that are indistinguishable from real ones, so it tries to minimize the discriminator's ability to differentiate between real and generated images.\n",
    "\n",
    "Step 2: Discriminator's Training: The discriminator receives both real images and generated images and assigns probabilities indicating how real or fake each image is. The discriminator aims to correctly classify images as real or generated. It's trained to maximize its ability to differentiate between the two.\n",
    "\n",
    "Iteration: Steps 1 and 2 are repeated iteratively. The generator improves its ability to produce more realistic images over time, while the discriminator becomes better at telling real from fake images.\n",
    "\n",
    "Loss Functions:\n",
    "Generator Loss: The generator's loss is calculated based on the discriminator's assessment of the generated images. The generator tries to minimize this loss, aiming to generate images that the discriminator can't easily distinguish from real ones.\n",
    "\n",
    "Discriminator Loss: The discriminator's loss measures its ability to correctly classify real and generated images. It aims to minimize this loss by getting better at distinguishing between the two.\n",
    "\n",
    "Evaluation and Use:\n",
    "The training continues until a satisfactory level of image quality is achieved, or until a certain number of training iterations have passed. Once trained, the generator can be used to generate images with the desired transformation. For instance, a well-trained image-to-image translation GAN can take a daytime photo and transform it into a nighttime version, effectively translating the scene from one domain to another.\n",
    "\n",
    "Overall, the generator and discriminator work in a competitive manner to push each other to improve. This adversarial process helps the generator learn to produce high-quality images that are consistent with the desired transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start coding referring the theory above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m x\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m(x,y)\n",
      "File \u001b[1;32mc:\\Users\\dsouzm3\\OneDrive - Dell Technologies\\Documents 1\\GitHub\\artificial-intelligence\\.venv\\lib\\site-packages\\matplotlib\\_api\\__init__.py:226\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m props:\n\u001b[0;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m props[name]\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance)\n\u001b[1;32m--> 226\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= [1,2,3,5]\n",
    "y = [3,5,7,2]\n",
    "\n",
    "plt.plot(x,y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "910af7984850755e3cc11f19cd480385748a45953ba277578d4f2365a2ca813e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
